<div id="readability-page-1" class="page"><h3 class="title" data-translation="<span>Die &quot;Killerroboter&quot; -Debatte, die Realität geworden ist</span>">현실이 돼 버린 ‘킬러 로봇’ 논쟁</h3><article>
                                        
                                        
                                        <p data-translation="<span>Registrierung: 2018.04.05 19:13 Änderung: 2018.04.05 19:38</span>">등록 : 2018.04.05 19:13
                                            
                                                수정 : 2018.04.05 19:38
                                                
                                            </p>
                                    </article><article id="article-body">

                                        

                                        <article>
                                            <div>
                                                <center>

                                        <img src="http://image.hankookilbo.com/i.aspx?Guid=3c74dd92cbce4befaf94d6fea41a1f01&amp;Month=201804&amp;size=640" alt="">

                                         </center>
                                            </div>

                                            <p data-translation="<span>Propaganda des Films 'Terminator: Der Beginn des zukünftigen Krieges'</span>">영화 ‘터미네이터: 미래 전쟁의 시작’ 의 선전물</p>

                                        </article>
                                        
                                              
                                        
                                        <p data-translation="<span>&quot;Eine Maschine kann einen Mann durch sein eigenes Urteil töten.&quot;</span>">“기계가 스스로의 판단 만으로 사람을 죽일 수 있나.”
</p><p data-translation="<span>Die Frage nach der Hollywood-Serie &quot;Terminator&quot;, die vor 34 Jahren nur als Science-Fiction-Film behandelt wurde, entstand 2018 als Thema für die Menschheit.</span>">34년전 공상과학영화로만 취급받았던 헐리우드 영화 ‘터미네이터’ 시리즈의 질문이 2018년 인류에게 실존 문제로 다가왔다.</p><p data-translation="<span>Stärkerer menschlicher Wunsch nach Waffen künstliche Intelligenz (<span id=&quot;_0&quot;>KI</span>während SOLiD als Waffen der Selbstbestimmung der Montage) und der Antrieb Ethik in der Wissenschaft debattieren Klettern geflohen. Darüber hinaus ist der Mittelpunkt der Kontroverse, die state-of-the-art - Unternehmen Google im Silicon Valley sowie Halten Sie das Symbol oben fing das Korea Institute of Science and Technology, Korea Advanced Institute of Science and Technology (KAIST).</span>">더 강한 무기에 대한 인간 욕망이 인공지능(<span id="_0" data-translation="KI">AI</span>)을 장착해 스스로 판단하고 구동하는 무기 개발로 쏠리면서, 과학자 집단에서 윤리 논쟁이 달아오르기 시작했다. 게다가 논쟁의 중심에는 미국 실리콘밸리의 최첨단 기업 구글은 물론이고 한국 과학기술의 상징인 한국과학기술원(카이스트)까지 휘말려 들고 있다.</p><p data-translation="<span>Die New York Times (<span id=&quot;_1&quot;>NYT</span>) berichtete am Dienstag (4. April ) über eine Petition, die von 3.100 Googler-Mitarbeitern unterzeichnet wurde, darunter Dutzende von Top-Ingenieuren , um sie an<span id=&quot;_2&quot;>CEO</span>Sundar Pisai zu senden. Der Inhalt war einfach. &quot;Wir glauben, dass Google keinen Krieg führen sollte.&quot; Die kollektive Aktion der Google-Mitarbeiter ist auf das Pentagon des Unternehmens und das laufende &quot;Maven&quot; -Projekt zurückzuführen. Maven ist ein Pentagon-Pilotprogramm, das darauf abzielt, die Schlagkraft unbemannter Kampfflugzeuge der US Air Force (Drohnen) mit Googles Cloud-basierter<span id=&quot;_3&quot;>KI-</span>Technologie zu verbessern.</span>">뉴욕타임스(<span id="_1" data-translation="NYT">NYT</span>)는 4일(현지시간) 최고위급 엔지니어 수십명을 포함, 구글직원 3,100명이 서명해 순다르 피차이 최고경영자(<span id="_2" data-translation="CEO">CEO</span>)에게 보낼 청원서를 보도했다. 내용은 간단했다. “우리는 구글이 전쟁 사업에 참여해선 안 된다고 믿는다”였다. 구글 직원의 집단 행동은 이 회사가 미 국방부(펜타곤)와 진행 중인 ‘메이븐’ 프로젝트 때문이다. 메이븐은 구글의 클라우드 기반 인공지능(<span id="_3" data-translation="KI-">AI</span>) 기술로 미 공군 무인전투기(드론)의 타격 능력 향상을 꾀하려는 펜타곤의 파일럿 프로그램이다.

</p><p data-translation="<span><span id=&quot;_4&quot;></span>Laut der NYT ist die Nachricht von Google-Ingenieuren klar. Auch wenn der Gegenstand zum Leben zu töten , die Feinde Zweck<span id=&quot;_5&quot;>KI</span>- Technologie ist „nicht böse werden Sie (<span id=&quot;_6&quot;>nicht</span> <span id=&quot;_7&quot;>sein</span> <span id=&quot;_8&quot;>Übel</span>ist , dass die Front - Layout mit den Zielen der Organisation, Google Talk). &quot;Es ist inakzeptabel, ein militärisches Überwachungssystem aufzubauen, das katastrophale Folgen für die Zusammenarbeit mit der Regierung haben kann&quot;, sagte er.<span id=&quot;_9&quot;>NYT</span>auch „<span id=&quot;_10&quot;>AI</span>wurde als kulturelle Auseinandersetzungen statt zwischen Silicon Valley und der Regierung haben Technologie im Einsatz von Technologie für militärische Zwecke ist eine wachsende Zahl von Situationen voran analysiert.“</span>"><span id="_4" data-translation="">NYT</span>에 따르면 구글 엔지니어들의 메시지는 뚜렷하다. 아무리 적군을 대상으로 한다 해도 인명살상이 목적인 <span id="_5" data-translation="KI">AI</span> 기술 개발은 ‘사악해지지 말자(<span id="_6" data-translation="nicht">Don’t</span> <span id="_7" data-translation="sein">be</span> <span id="_8" data-translation="Übel">Evil</span>)’인 구글 조직의 목표와 정면 배치된다는 얘기다. 이들은 “정부에 협력한다는 명분으로 군사적 감시, 나아가 치명적인 결과를 낳을 수도 있는 기술을 구축하는 것은 받아들일 수 없다”고 밝혔다. <span id="_9" data-translation="NYT">NYT</span>도 “<span id="_10" data-translation="AI">AI</span> 기술의 군사 목적 활용이 점점 늘어나는 상황에서 첨단 기술을 보유한 실리콘밸리와 정부 간에 벌어지는 문화적 충돌”이라고 분석했다.

</p><p data-translation="<span>Leider war Korea am selben Tag in der &quot;Terminator&quot; -Debatte gefangen. Fünfzig ausländische prominente Roboterforscher schickten einen Warnbrief an KAIST. Inception war aufgrund KAIST und Hanwha System Co-Standorten Ende Februar Defense Research Center for Artificial Intelligence Fusion. Britische Financial Times (<span id=&quot;_11&quot;>FT</span>aus dem Schreiben von) die öffentlichen Roboter Wissenschaftler Killer - Roboter betreffen ‚und direkt erwähnt‘ eine Verpflichtung , dass sie nicht Waffen autonomer Entscheidungen ohne menschliche sinnvolle Kontrolle , bis der KAIST Präsidenten entwickeln wir sie kündigte an, es würde alle Zusammenarbeit an die Front verweigern. &quot;</span>">공교롭게 같은 날 한국도 ‘터미네이터’ 논쟁에 휘말렸다. 외국의 저명한 로봇학자 50명이 카이스트에 경고 서한을 보낸 것. 발단은 카이스트와 한화시스템이 지난 2월 말 공동 개소한 ‘국방인공지능융합연구센터’ 때문이었다. 영국 파이낸셜타임스(<span id="_11" data-translation="FT">FT</span>)가 공개한 서한에서 로봇학자들은 ‘킬러로봇 우려’까지 직접 거론하며, “인간의 유의미한 통제 없이 자율적으로 결정하는 무기를 개발하지 않겠다는 확약을 카이스트 총장이 할 때까지 우리는 모든 공동연구를 전면 거부할 것”이라고 선언했다. 

</p><p data-translation="<span>KAIST hat nicht die Absicht, einen Killer-Roboter zu entwickeln. Schule Beamten erklärten, dass „die im letzten Monat am 19. verbrachte, Angriff mit Massenvernichtungswaffen oder einem Killer-Roboter Ziel der Forschung ist nicht getan‚Präsident, der die offiziellen Namen“. Darüber hinaus „noch einmal betont, dass die Kontrolle nicht Forschungsaktivitäten im Gegensatz zur Würde des Menschen, wie das Fehlen von autonomen Waffen durchführen wird“, sagte er.</span>">카이스트는 킬러 로봇 개발 의사가 전혀 없다는 입장이다. 학교 관계자는 “지난달 19일 ‘공격용 대량살상 무기나 킬러 로봇 개발 목적의 연구 수행이 아니다’라는 총장 명의의 공문을 보냈다”고 해명했다. 또 “통제력이 결여된 자율무기 개발 등 인간 존엄성에 어긋나는 연구활동을 수행하지 않을 것임을 다시 한번 강조한다”고 밝혔다.

</p><p data-translation="<span>Experten analysieren die Kontroverse in Google und KAIST als Beginn einer &quot;Terminator&quot; -Debatte, die noch lange andauern wird. UN bestimmte konventionelle Waffen - Übereinkommen (November<span id=&quot;_12&quot;>CCW</span>aus) Konferenz<span id=&quot;_13&quot;>AI</span>, aber die beiden Maßnahmen geladen Waffen Debatte um die UN - Experten zu verbieten und NGOs bar, spielen Ingenieure eine echte Entwicklung offiziell die ethische Frage aufgeworfen hat Dies ist, weil dies das erste Mal ist.</span>">전문가들은 구글과 카이스트에서 벌어진 논쟁이 향후 상당기간 이어질 ‘터미네이터’ 논쟁의 시작으로 분석하고 있다. 지난해 11월 유엔 특정재래식무기금지협약(<span id="_12" data-translation="CCW">CCW</span>) 회의에서 <span id="_13" data-translation="AI">AI</span> 탑재 무기를 금지하는 방안이 유엔 전문가들과 시민단체를 중심으로 논의된 바 있지만, 실제 개발을 담당할 엔지니어들이 공식적으로 윤리 문제를 제기한 것은 이번이 처음이기 때문이다. 

</p><p data-translation="<span>Zivile Aktivisten<span id=&quot;_14&quot;>fordern</span>aus humanitären Gründen starke gesetzliche Beschränkungen für KI- Waffen, aber Experten zeigen eine düstere Perspektive. Humanity Gier über die Großzügigkeit der<span id=&quot;_15&quot;>KI-</span>Technologie, gute Waffen und das Misstrauen gegenüber dem Feind, der eine unaufhaltsame militärische Konkurrenz ist. Australiens prominenter Philosoph Peter Singer sagte: &quot;Geldbewusste Militärunternehmen und geopolitische Konkurrenz in jedem Land können den<span id=&quot;_16&quot;>KI-</span>Waffenwettbewerb beschleunigen.&quot; Der ehemalige US-Verteidigungsminister James Miller sagte auch: &quot;Die Vereinigten Staaten haben nicht die Waffen, die die<span id=&quot;_17&quot;>KI</span>automatisch richten wird, aber wenn Feinde wie Russland oder China mächtige Waffen mit<span id=&quot;_18&quot;>KI</span>vorbereiten, wird die Reaktion anders sein.&quot;</span>">시민운동가들은 인도주의적 차원에서 <span id="_14" data-translation="fordern">AI</span> 무기에 대한 강력한 법적 규제를 주장하고 있으나, 전문가들은 우울한 전망을 내놓고 있다. <span id="_15" data-translation="KI-">AI</span> 기술의 범용성과 우수한 무기에 대한 인간의 탐욕, 그리고 적국에 대한 불신 때문에 멈출 수 없는 군비경쟁이 우려된다는 것이다. 호주의 저명한 철학자 피터 싱어는 “돈에 눈이 먼 군수업자, 각국의 지정학적 경쟁 등이 <span id="_16" data-translation="KI-">AI</span> 무기 경쟁을 가속화시킬 수 있다”고 말했다. 제임스 밀러 전 미국 국방부 차관보도 “미국은 <span id="_17" data-translation="KI">AI</span>가 자동 판단하는 무기를 갖지 않는 게 원칙이지만, 러시아 혹은 중국 같은 적국이 <span id="_18" data-translation="KI">AI</span>를 장착한 강력한 무기를 준비한다면 그 대응은 달라질 것”이라고 우려했다.

</p><p data-translation="<span>Noch bevor die Antwort auf die ethische Frage der Menschheit ‚Maschinenwerkstatt muss wirklich beurteilen für sich zu finden , auf danghanga einen Menschen zu töten,<span id=&quot;_19&quot;>AI</span>wird wahrscheinlich Technologie ohne angemessene Kontrollen bis ins Unendliche verlängert werden.</span>">‘기계가 스스로 판단해 인간을 살해하는 게 과연 온당한가’라는 윤리적 질문에 인류가 해답을 찾기도 전에 <span id="_19" data-translation="AI">AI</span>기술이 적절한 통제 없이 무한대로 확장될 가능성이 높다는 것이다.


</p><p data-translation="<span>Haha Tae Reporter thheo@hankookilbo.com</span>">허택회 기자 

                                            thheo@hankookilbo.com


</p><p data-translation="<span>Kim Jung Woo Reporter wookim@hankookilbo.com</span>">김정우 기자 wookim@hankookilbo.com




                                        </p>

                                    </article><article>
                                        
                                        <p data-translation="<span>Copyright © Korea Times Zeitung Alle Rechte vorbehalten und Weiterverbreitung verboten</span>">
                                            저작권자 © 한국일보 무단전재 및 재배포 금지
                                        </p>
                                    </article></div>