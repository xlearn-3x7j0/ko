<div id="readability-page-1" class="page"><h3 class="title" data-translation="<span><span id=&quot;_0&quot;>Si une</span>arme de l' IA a commis un crime anti-humain, qui est responsable?</span>"><span id="_0" data-translation="Si une">AI</span> 무기가 반인류 범죄를 저지른다면 책임자는 누구?</h3><div>
                                        <p data-translation="<span>
                                            </span>">
                                            </p><h4 data-translation="<span><span id=&quot;_1&quot;>Si une</span>arme de l' IA a commis un crime anti-humain, qui est responsable?</span>"><span id="_1" data-translation="Si une">AI</span> 무기가 반인류 범죄를 저지른다면 책임자는 누구?</h4>

                                        <p data-translation="<span></span>"></p>


                                    </div><article>
                                        
                                        
                                        <p data-translation="<span>Inscription: 2018.04.05 18:14 Révision: 2018.04.05 18:15</span>">등록 : 2018.04.05 18:14
                                            
                                                수정 : 2018.04.05 18:15
                                                
                                            </p>
                                    </article><article id="article-body">

                                        

                                        <article>
                                            <div>
                                                <center>

                                        <img src="http://image.hankookilbo.com/i.aspx?Guid=966b2343c2374a788357df4a620c099b&amp;Month=201803&amp;size=640" alt="">

                                         </center>
                                            </div>

                                            <p data-translation="<span>Getty Images Bank</span>">게티이미지뱅크</p>

                                        </article>
                                        
                                              
                                        
                                        <p data-translation="<span>Des experts mondiaux Robot KAIST (<span id=&quot;_2&quot;>LE KAIST</span>) Défense de l' intelligence artificielle (<span id=&quot;_3&quot;>IA</span>) centres de recherche de fusion<span id=&quot;_4&quot;>AI</span>et a exprimé son inquiétude que le développement de l'utilisation de « robots mortels<span id=&quot;_5&quot;>AI</span>controverse a été rythmé autour de l'éthique.</span>">세계 로봇 전문가들이 카이스트(<span id="_2" data-translation="LE KAIST">KAIST</span>) 국방인공지능(<span id="_3" data-translation="IA">AI</span>) 융합연구센터가 <span id="_4" data-translation="AI">AI</span>를 활용한 ‘살상 로봇’을 개발할 수 있다고 우려를 표하면서 <span id="_5" data-translation="AI">AI</span> 윤리를 둘러싼 논란이 불거지고 있다.</p><p data-translation="<span>Outre les « armes d'autodestruction , il ne sera pas la recherche est contraire à la dignité humaine » est la clarification KAIST, dans le monde entier<span id=&quot;_6&quot;>AI</span>éthique établies dans la situation encore tout - petits<span id=&quot;_7&quot;>AI</span>craint que des problèmes imprévus , etc. dysfonctionnement et d' abus peuvent bulgeojil En.</span>">“자율살상무기 등 인간의 존엄성에 반하는 연구를 하지 않을 것”이란 카이스트 해명과는 별개로, 전 세계적으로 <span id="_6" data-translation="AI">AI</span> 윤리 제정이 아직 걸음마인 상황에서 <span id="_7" data-translation="AI">AI</span> 오작동ㆍ남용 등으로 예기치 못한 문제가 불거질 수 있다는 우려에서다.</p><p data-translation="<span>Contrairement à la technologie de l'<span id=&quot;_8&quot;>IA qui</span>évolue rapidement , la question de l'éthique de l'<span id=&quot;_9&quot;>IA</span>est encore à un niveau élémentaire. «L' éthique de l'<span id=&quot;_10&quot;>IA</span>est divisée en éthique du développeur, éthique de l'utilisateur et éthique que l'<span id=&quot;_11&quot;>IA</span>doit suivre, à l'exception de l'éthique du développeur », a déclaré le représentant de Hansang Tech Frontier .</span>">비약적으로 발전하는 <span id="_8" data-translation="IA qui">AI</span> 기술과 달리, <span id="_9" data-translation="IA">AI</span> 윤리 문제는 아직 초보적인 수준에 머물러 있다. 한상기 테크프론티어 대표는 "<span id="_10" data-translation="IA">AI</span> 윤리는 개발자 윤리, 사용자 윤리, <span id="_11" data-translation="IA">AI</span>가 지켜야 할 윤리 등으로 구분되는데, 개발자 윤리를 제외하곤 아직 별다른 진전이 없다"고 말했다. 

</p><p data-translation="<span>Les experts réunis à Rome dernière 1-acyl California United mai<span id=&quot;_12&quot;>AI</span>« Asilomar contenant les 23 directions, y compris la direction D<span id=&quot;_13&quot;>AI</span>Principe naenwat », mais tous<span id=&quot;_14&quot;>AI</span>est sur les développeurs. Dans ce principe, nous devons développer une intelligence intelligente, non intelligente, nous devons concevoir l' intelligence<span id=&quot;_15&quot;>artificielle</span>pour répondre aux valeurs humaines, nous devons éviter la concurrence des armes automatiques avec l' intelligence<span id=&quot;_16&quot;>artificielle</span>. Plus de 2 300 professionnels, dont le PDG Ilren Musk Tesla , le Dr. Stephen Hawking récemment, et le<span id=&quot;_17&quot;>PDG</span>de Google Deep Mind de Demise Hausbys, Alpha<span id=&quot;_18&quot;>Corporation</span>, l'ont signé.</span>">지난해 1월 미국 캘리포니아 아실로마에서 전문가들이 모여 <span id="_12" data-translation="AI">AI</span> 연구개발 방향 등 23개 방향을 담은 '아실로마 <span id="_13" data-translation="AI">AI</span> 원칙'을 내놨지만, 모두 <span id="_14" data-translation="AI">AI</span> 개발자에 대한 내용이다. 이 원칙에도 ▦방향성이 없는 지능이 아니라 유익한 지능을 개발한다 ▦인류의 가치에 부합하는 쪽으로 <span id="_15" data-translation="artificielle">AI</span>를 설계해야 한다 ▦<span id="_16" data-translation="artificielle">AI</span>를 이용한 자동화 무기 경쟁은 피해야 한다 같은 선언적 내용이 담겼을 뿐이다. 일론 머스크 테슬라 최고경영자(<span id="_17" data-translation="PDG">CEO</span>), 최근 작고한 스티븐 호킹 박사, 알파고를 개발한 데미스 허사비스 구글 딥마인드 <span id="_18" data-translation="Corporation">CEO</span> 등 2,300여명의 전문가가 여기에 서명했다. 

</p><p data-translation="<span>Jangwooseok Hyundai Economic Research Institute chercheur, « drones (UAV) dans le bombardement en appuyant sur le dernier bouton de lancement de missiles<span id=&quot;_19&quot;>AI</span>congé laissera un grand débat dans la communauté internationale » et « Still<span id=&quot;_20&quot;>AI</span>éthique à respecter et les normes universelles que l'Internationale est Il est possible que si l'<span id=&quot;_21&quot;>on</span>donne à l' IA des fonctions autonomes de prise de décision même si aucun accord n'est atteint, il y aura des situations dans lesquelles elle ne peut pas être contrôlée. &quot;</span>">장우석 현대경제연구원 연구위원은 “드론(무인기) 폭격에서 마지막 미사일 발사 버튼을 누르는 것까지 <span id="_19" data-translation="AI">AI</span>에게 맡길 것인가를 두고 국제사회의 논란이 크다”며 “아직 <span id="_20" data-translation="AI">AI</span>가 지켜야 할 윤리ㆍ보편적 규범이 무엇인지 국제합의조차 이뤄지지 않은 상황에서 <span id="_21" data-translation="on">AI</span>에게 자율의사 결정 기능까지 부여하면 통제할 수 없는 상황이 발생할 수도 있다”고 우려했다. 

</p><p data-translation="<span>Pour cette raison, le Conseil des droits de l'homme de l'ONU recommande des tests d'armes autodestructeurs, la production et le transfert de technologie jusqu'à ce que les normes internationales soient établies. Kim Yoon-jung, chercheur à l'Institut coréen d'évaluation et de planification de la science et de la technologie, a déclaré: « Plus<span id=&quot;_22&quot;>la</span>technologie de l' IA se développe, plus la prise de décision autonome de l'<span id=&quot;_23&quot;>IA</span>peut nuire à l'humanité. Si vous donnez à<span id=&quot;_24&quot;>AI</span>le droit d'enfreindre, cela causera une grande confusion dans la société. &quot;</span>">이런 이유로 유엔 인권이사회는 관련한 국제규범이 형성되기 전까지 자율살상무기 실험ㆍ생산ㆍ기술이전 자제를 권고하고 있다. 김윤정 한국과학기술기획평가원 연구위원도 "<span id="_22" data-translation="la">AI</span> 기술이 발달할수록 <span id="_23" data-translation="IA">AI</span>가 자율적으로 내린 의사결정이 인류에게 해를 끼치는 경우가 증대될 수 있다"며 "자율살상무기시스템이나 경찰 로봇 등 인류의 기본권을 직접 침해할 수 있는 권한까지 <span id="_24" data-translation="AI">AI</span>에게 부여한다면 사회에 큰 혼란을 가져올 것"이라고 말했다. 

</p><p data-translation="<span><span id=&quot;_25&quot;></span>Qui sera puni quand Amnesty International commet des crimes contre l'humanité est toujours un problème. La science et la technologie « questions juridiques et éthiques de l' ère de l' intelligence artificielle » récents de la politique de l' Institut des rapports &quot;<span id=&quot;_26&quot;>AI</span>lorsque le robot iphyeoteul blessures à une autre personne, conformément à l'instruction du propriétaire Jilji ses responsabilités maître robot, de suivre une mauvaise commande<span id=&quot;_27&quot;>AI</span>producteurs ont fait une Et si cela devrait être fait. &quot;</span>"><span id="_25" data-translation="">AI</span>가 인륜에 반하는 범죄를 저질렀을 때 누구를 처벌할 것인지도 아직 미해결 과제다. 과학기술정책연구원은 최근 '인공지능 시대의 법적ㆍ윤리적 쟁점' 보고서에서 "<span id="_26" data-translation="AI">AI</span> 로봇이 소유주의 명령에 따라 타인에게 상해를 입혔을 때 그 책임을 로봇 주인이 질지, 잘못된 명령을 따르도록 <span id="_27" data-translation="AI">AI</span>를 만든 제작자가 져야 하는지 등이 향후 쟁점이 될 것"이라고 내다봤다. 

</p><p data-translation="<span><span id=&quot;_28&quot;>Comme la</span>question de l'éthique de l' IA est devenue une tâche urgente, des universités de renommée internationale mettent en place<span id=&quot;_29&quot;>des</span>cours d'éthique de l' IA pour encourager les spécialistes . L'Université Harvard et le Massachusetts Institute of Technology (<span id=&quot;_30&quot;>MIT</span>) vont commencer une conférence conjointe sur<span id=&quot;_31&quot;>la</span>réglementation et l'éthique de l' IA cette année . L'Université de Stanford se prépare à ouvrir un cours sur «l'éthique des sciences informatiques» qui débutera l'année prochaine. Kim a déclaré: «Les règlements de l'industrie qui empêchent le développement de l'<span id=&quot;_32&quot;>IA</span>devraient être résolus, mais les règles d'éthique devraient être gardées à l'esprit.</span>"><span id="_28" data-translation="Comme la">AI</span> 윤리 제정 문제가 시급한 과제로 떠오른 만큼, 해외 유명 대학에선 전문가 양성을 위해 속속 <span id="_29" data-translation="des">AI</span> 윤리 과목을 개설하고 있다. 미국 하버드대와 매사추세츠공대(<span id="_30" data-translation="MIT">MIT</span>)는 올해부터 <span id="_31" data-translation="la">AI</span> 규제와 윤리를 주제로 공동 강의를 시작한다. 미국 스탠퍼드대는 내년 개강을 목표로 '컴퓨터 사이언스 윤리학' 과목 개설을 준비 중이다. 김 연구위원은 "<span id="_32" data-translation="IA">AI</span> 발전을 가로막는 산업규제는 풀어야 하지만, 윤리 규제는 이와 별로도 생각하고 계속 고민해야 한다"고 말했다. 

</p><p data-translation="<span>Par Tae-Sup Tae libertas@hankookilbo.com</span>">변태섭기자 libertas@hankookilbo.com


                                        </p>

                                    </article><article>
                                        
                                        <p data-translation="<span>Copyright © Korea Times Newspaper Tous droits réservés et redistribution interdite</span>">
                                            저작권자 © 한국일보 무단전재 및 재배포 금지
                                        </p>
                                    </article></div>